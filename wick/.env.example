# ──────────────────────────────────────────────────────────────
# LLM Provider Keys (set for cloud providers)
# ──────────────────────────────────────────────────────────────
ANTHROPIC_API_KEY=your-anthropic-api-key
OPENAI_API_KEY=your-openai-api-key

# ──────────────────────────────────────────────────────────────
# Local Models — Ollama
# ──────────────────────────────────────────────────────────────
OLLAMA_BASE_URL=http://localhost:11434

# ──────────────────────────────────────────────────────────────
# Gateway — OpenAI-compatible proxy (LiteLLM, vLLM, TGI, etc.)
# ──────────────────────────────────────────────────────────────
GATEWAY_BASE_URL=http://localhost:4000/v1
GATEWAY_API_KEY=

# ──────────────────────────────────────────────────────────────
# Tool API Keys
# ──────────────────────────────────────────────────────────────
TAVILY_API_KEY=your-tavily-api-key

# ──────────────────────────────────────────────────────────────
# Agent Defaults
# ──────────────────────────────────────────────────────────────
DEFAULT_MODEL=ollama:llama3.1:8b
DEFAULT_SYSTEM_PROMPT=You are a helpful AI assistant with planning, file management, and research capabilities.
DEFAULT_BACKEND=state
DEFAULT_DEBUG=false

# ──────────────────────────────────────────────────────────────
# Server
# ──────────────────────────────────────────────────────────────
HOST=0.0.0.0
PORT=8000
